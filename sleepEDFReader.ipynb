{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install mne"
      ],
      "metadata": {
        "id": "ylft-d_uOtAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import ntpath\n",
        "import argparse\n",
        "import shutil\n",
        "import math\n",
        "from datetime import datetime\n",
        "from mne.io import read_raw_edf\n",
        "from collections import namedtuple\n",
        "import re, datetime, operator, logging, sys"
      ],
      "metadata": {
        "id": "9uH_0rVLM1Un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EVENT_CHANNEL = 'EDF Annotations'\n",
        "log = logging.getLogger(__name__)\n",
        "\n",
        "class EDFEndOfData(Exception): pass\n",
        "\n",
        "\n",
        "def tal(tal_str):\n",
        "    '''Return a list with (onset, duration, annotation) tuples for an EDF+ TAL\n",
        "    stream.\n",
        "    '''\n",
        "    exp = '(?P<onset>[+\\-]\\d+(?:\\.\\d*)?)' + \\\n",
        "        '(?:\\x15(?P<duration>\\d+(?:\\.\\d*)?))?' + \\\n",
        "        '(\\x14(?P<annotation>[^\\x00]*))?' + \\\n",
        "        '(?:\\x14\\x00)'\n",
        "\n",
        "    def parse(dic):\n",
        "        return (\n",
        "        float(dic['onset']),\n",
        "        float(dic['duration']) if dic['duration'] else 0.,\n",
        "        str(dic['annotation'].encode('utf-8')).split('\\x14') if dic['annotation'] else [])\n",
        "\n",
        "    return [parse(m.groupdict()) for m in re.finditer(exp, tal_str)]\n",
        "\n",
        "\n",
        "class EDFHeaderParser:\n",
        "    def parse_edf_header(f):\n",
        "        h = {}\n",
        "        assert f.tell() == 0  # check file position\n",
        "        assert f.read(8) == '0       '\n",
        "\n",
        "        # recording info)\n",
        "        h['local_subject_id'] = f.read(80).strip()\n",
        "        h['local_recording_id'] = f.read(80).strip()\n",
        "\n",
        "        # parse timestamp\n",
        "        (day, month, year) = [int(x) for x in re.findall('(\\d+)', f.read(8))]\n",
        "        (hour, minute, sec)= [int(x) for x in re.findall('(\\d+)', f.read(8))]\n",
        "        h['date_time'] = str(datetime.datetime(year + 2000, month, day,\n",
        "                                            hour, minute, sec))\n",
        "\n",
        "        # misc\n",
        "        header_nbytes = int(f.read(8))\n",
        "        subtype = f.read(44)[:5]\n",
        "        h['EDF+'] = subtype in ['EDF+C', 'EDF+D']\n",
        "        h['contiguous'] = subtype != 'EDF+D'\n",
        "        h['n_records'] = int(f.read(8))\n",
        "        h['record_length'] = float(f.read(8))  # in seconds\n",
        "        nchannels = h['n_channels'] = int(f.read(4))\n",
        "\n",
        "        # read channel info\n",
        "        channels = range(h['n_channels'])\n",
        "        h['label'] = [f.read(16).strip() for n in channels]\n",
        "        h['transducer_type'] = [f.read(80).strip() for n in channels]\n",
        "        h['units'] = [f.read(8).strip() for n in channels]\n",
        "        h['physical_min'] = np.asarray([float(f.read(8)) for n in channels])\n",
        "        h['physical_max'] = np.asarray([float(f.read(8)) for n in channels])\n",
        "        h['digital_min'] = np.asarray([float(f.read(8)) for n in channels])\n",
        "        h['digital_max'] = np.asarray([float(f.read(8)) for n in channels])\n",
        "        h['prefiltering'] = [f.read(80).strip() for n in channels]\n",
        "        h['n_samples_per_record'] = [int(f.read(8)) for n in channels]\n",
        "        f.read(32 * nchannels)  # reserved\n",
        "        return h\n",
        "\n",
        "\n",
        "class SleepEDFReader:\n",
        "    def __init__(self, file, header_parser=EDFHeaderParser()):\n",
        "        self.file = file\n",
        "        self.parser = header_parser\n",
        "        self.header = self.parser.parse_edf_header(self.file)\n",
        "        self.digital_min, self.physical_min, self.gain = None, None, None\n",
        "        self.get_ranges()\n",
        "\n",
        "    def get_ranges(self):\n",
        "        self.digital_min, self.physical_min = self.header['digital_min'], self.header['physical_min']\n",
        "        ranges = [self.header['digital_max'] - self.digital_min, self.header['physical_max'] - self.physical_min]\n",
        "        assert np.all(ranges > 0)\n",
        "        self.gain = ranges[1]/ranges[0]\n",
        "\n",
        "    def read_one_record(self):\n",
        "        dig_min, phys_min, gain = self.dig_min, self.phys_min, self.gain\n",
        "        time = float('nan')\n",
        "        signals = []\n",
        "        events = []\n",
        "        raw_record = []\n",
        "        for nsamp in self.header['n_samples_per_record']:\n",
        "            samples = self.file.read(nsamp * 2)\n",
        "            if len(samples) != nsamp * 2:\n",
        "                raise EDFEndOfData\n",
        "            result.append(samples)\n",
        "        for (i, samples) in enumerate(raw_record):\n",
        "            if self.header['label'][i] == EVENT_CHANNEL:\n",
        "                ann = tal(samples)\n",
        "                time = ann[0][0]\n",
        "                events.extend(ann[1:])\n",
        "                # print(i, samples)\n",
        "                # exit()\n",
        "            else:\n",
        "                # 2-byte little-endian integers\n",
        "                dig = np.fromstring(samples, '<i2').astype(np.float32)\n",
        "                phys = (dig - dig_min[i]) * gain[i] + phys_min[i]\n",
        "                signals.append(phys)\n",
        "\n",
        "        return time, signals, events\n",
        "\n",
        "        def retrieve_records(self):\n",
        "            '''\n",
        "            Record generator.\n",
        "            '''\n",
        "            try:\n",
        "                while True:\n",
        "                    yield self.read_record()\n",
        "            except EDFEndOfData:\n",
        "                pass\n",
        "\n",
        "\n",
        "class BaseEDFReader:\n",
        "    def __init__(self, file):\n",
        "        self.file = file\n",
        "\n",
        "    def read_header(self):\n",
        "        self.header = parse_edf_header(self.file)\n",
        "\n",
        "        # calculate ranges for rescaling\n",
        "        self.dig_min = self.header['digital_min']\n",
        "        self.phys_min = self.header['physical_min']\n",
        "        phys_range = self.header['physical_max'] - self.phys_min\n",
        "        dig_range = self.header['digital_max'] - self.dig_min\n",
        "        assert np.all(phys_range > 0)\n",
        "        assert np.all(dig_range > 0)\n",
        "        self.gain = phys_range / dig_range\n",
        "\n",
        "    def read_raw_record(self):\n",
        "        '''Read a record with data_2013 and return a list containing arrays with raw\n",
        "        bytes.\n",
        "        '''\n",
        "        result = []\n",
        "        for nsamp in self.header['n_samples_per_record']:\n",
        "            samples = self.file.read(nsamp * 2)\n",
        "            if len(samples) != nsamp * 2:\n",
        "                raise EDFEndOfData\n",
        "            result.append(samples)\n",
        "        return result\n",
        "\n",
        "\n",
        "    def convert_record(self, raw_record):\n",
        "        '''Convert a raw record to a (time, signals, events) tuple based on\n",
        "        information in the header.\n",
        "        '''\n",
        "        dig_min, phys_min, gain = self.dig_min, self.phys_min, self.gain\n",
        "        time = float('nan')\n",
        "        signals = []\n",
        "        events = []\n",
        "        for (i, samples) in enumerate(raw_record):\n",
        "            if self.header['label'][i] == EVENT_CHANNEL:\n",
        "                ann = tal(samples)\n",
        "                time = ann[0][0]\n",
        "                events.extend(ann[1:])\n",
        "                # print(i, samples)\n",
        "                # exit()\n",
        "            else:\n",
        "                # 2-byte little-endian integers\n",
        "                dig = np.fromstring(samples, '<i2').astype(np.float32)\n",
        "                phys = (dig - dig_min[i]) * gain[i] + phys_min[i]\n",
        "                signals.append(phys)\n",
        "\n",
        "        return time, signals, events\n",
        "\n",
        "\n",
        "    def read_record(self):\n",
        "        return self.convert_record(self.read_raw_record())\n",
        "\n",
        "\n",
        "    def records(self):\n",
        "        '''\n",
        "        Record generator.\n",
        "        '''\n",
        "        try:\n",
        "            while True:\n",
        "                yield self.read_record()\n",
        "        except EDFEndOfData:\n",
        "            pass\n",
        "\n",
        "\n",
        "def load_edf(edffile):\n",
        "    '''Load an EDF+ file.\n",
        "    Very basic reader for EDF and EDF+ files. While BaseEDFReader does support\n",
        "    exotic features like non-homogeneous sample rates and loading only parts of\n",
        "    the stream, load_edf expects a single fixed sample rate for all channels and\n",
        "    tries to load the whole file.\n",
        "    Parameters\n",
        "    ----------\n",
        "    edffile : file-like object or string\n",
        "    Returns\n",
        "    -------\n",
        "    Named tuple with the fields:\n",
        "        X : NumPy array with shape p by n.\n",
        "        Raw recording of n samples in p dimensions.\n",
        "        sample_rate : float\n",
        "        The sample rate of the recording. Note that mixed sample-rates are not\n",
        "        supported.\n",
        "        sens_lab : list of length p with strings\n",
        "        The labels of the sensors used to record X.\n",
        "        time : NumPy array with length n\n",
        "        The time offset in the recording for each sample.\n",
        "        annotations : a list with tuples\n",
        "        EDF+ annotations are stored in (start, duration, description) tuples.\n",
        "        start : float\n",
        "            Indicates the start of the event in seconds.\n",
        "        duration : float\n",
        "            Indicates the duration of the event in seconds.\n",
        "        description : list with strings\n",
        "            Contains (multiple?) descriptions of the annotation event.\n",
        "    '''\n",
        "    if isinstance(edffile, basestring):\n",
        "        with open(edffile, 'rb') as f:\n",
        "            return load_edf(f)  # convert filename to file\n",
        "\n",
        "    reader = SleepEDFReader(edffile)\n",
        "\n",
        "    log.debug('EDF header: %s' % reader.header)\n",
        "\n",
        "    # get sample rate info\n",
        "    nsamp = np.unique(\n",
        "        [n for (l, n) in zip(reader.header['label'], reader.header['n_samples_per_record'])\n",
        "        if l != EVENT_CHANNEL])\n",
        "    assert nsamp.size == 1, 'Multiple sample rates not supported!'\n",
        "    sample_rate = float(nsamp[0]) / reader.header['record_length']\n",
        "\n",
        "    rectime, X, annotations = zip(*reader.records())\n",
        "    X = np.hstack(X)\n",
        "    annotations = reduce(operator.add, annotations)\n",
        "    chan_lab = [lab for lab in reader.header['label'] if lab != EVENT_CHANNEL]\n",
        "\n",
        "    # create timestamps\n",
        "    if reader.header['contiguous']:\n",
        "        time = np.arange(X.shape[1]) / sample_rate\n",
        "    else:\n",
        "        reclen = reader.header['record_length']\n",
        "        within_rec_time = np.linspace(0, reclen, nsamp, endpoint=False)\n",
        "        time = np.hstack([t + within_rec_time for t in rectime])\n",
        "\n",
        "    tup = namedtuple('EDF', 'X sample_rate chan_lab time annotations')\n",
        "    return tup(X, sample_rate, chan_lab, time, annotations)"
      ],
      "metadata": {
        "id": "Zgv2KoddQGMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpUBmjihMijb"
      },
      "outputs": [],
      "source": [
        "# Constants for sleep stages\n",
        "W = 0           # Wakefulness stage\n",
        "N1 = 1          # Non-REM stage 1\n",
        "N2 = 2          # Non-REM stage 2\n",
        "N3 = 3          # Non-REM stage 3\n",
        "REM = 4         # Rapid Eye Movement (REM) stage\n",
        "UNKNOWN = 5     # Unknown or unspecified stage\n",
        "\n",
        "EPOCH_SEC_SIZE = 30  # Duration of each sleep stage epoch in seconds\n",
        "\n",
        "# Function to map annotation strings to sleep stage labels\n",
        "def get_sleep_stage_label(ann_str):\n",
        "    ann_str = ann_str[2:-1]\n",
        "    if ann_str in [\"Sleep stage W\", \"Sleep stage ?\"]:\n",
        "        return W\n",
        "    elif ann_str == \"Sleep stage 1\":\n",
        "        return N1\n",
        "    elif ann_str == \"Sleep stage 2\":\n",
        "        return N2\n",
        "    elif ann_str == \"Sleep stage 3\" or ann_str == \"Sleep stage 4\":\n",
        "        return N3\n",
        "    elif ann_str == \"Sleep stage R\":\n",
        "        return REM\n",
        "    else:\n",
        "        return UNKNOWN\n",
        "\n",
        "# Function to load data from PSG and annotation files\n",
        "def load_data(psg_fname, ann_fname, select_ch):\n",
        "    # Read PSG (Polysomnography) data from EDF file\n",
        "    raw = read_raw_edf(psg_fname, preload=True, stim_channel=None)\n",
        "    sampling_rate = raw.info['sfreq']\n",
        "\n",
        "    # Extract the selected channel's data\n",
        "    raw_ch_df = raw.to_data_frame(scaling_time=100.0)[select_ch]\n",
        "    raw_ch_df = raw_ch_df.to_frame()\n",
        "    raw_ch_df.set_index(np.arange(len(raw_ch_df)))\n",
        "\n",
        "    # Get header information from PSG file\n",
        "    with open(psg_fname, 'r', errors='ignore') as f:\n",
        "        reader_raw = BaseEDFReader(f)\n",
        "        reader_raw.read_header()\n",
        "        h_raw = reader_raw.header\n",
        "\n",
        "    raw_start_dt = datetime.strptime(h_raw['date_time'], \"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "    # Read annotation and its header from Hypnogram file\n",
        "    with open(ann_fname, 'r', errors='ignore') as f:\n",
        "        reader_ann = BaseEDFReader(f)\n",
        "        reader_ann.read_header()\n",
        "        h_ann = reader_ann.header\n",
        "        _, _, ann = zip(*reader_ann.records())\n",
        "\n",
        "    ann_start_dt = datetime.strptime(h_ann['date_time'], \"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "    # Ensure that PSG and annotation files start at the same time\n",
        "    assert raw_start_dt == ann_start_dt\n",
        "\n",
        "    # Initialize lists to store data and labels\n",
        "    remove_idx = []     # Indices of data to be removed\n",
        "    labels = []         # Sleep stage labels\n",
        "    label_idx = []      # Indices corresponding to labeled data\n",
        "\n",
        "    # Process annotations to extract sleep stage labels\n",
        "    for a in ann[0]:\n",
        "        onset_sec, duration_sec, ann_char = a\n",
        "        ann_str = \"\".join(ann_char)\n",
        "        label = get_sleep_stage_label(ann_str)\n",
        "\n",
        "        if label != UNKNOWN:\n",
        "            if duration_sec % EPOCH_SEC_SIZE != 0:\n",
        "                raise Exception(\"Something wrong\")\n",
        "            duration_epoch = int(duration_sec / EPOCH_SEC_SIZE)\n",
        "            label_epoch = np.ones(duration_epoch, dtype=np.int) * label\n",
        "            labels.append(label_epoch)\n",
        "            idx = int(onset_sec * sampling_rate) + np.arange(duration_sec * sampling_rate, dtype=np.int)\n",
        "            label_idx.append(idx)\n",
        "        else:\n",
        "            idx = int(onset_sec * sampling_rate) + np.arange(duration_sec * sampling_rate, dtype=np.int)\n",
        "            remove_idx.append(idx)\n",
        "\n",
        "    # Stack labels to create the label array\n",
        "    labels = np.hstack(labels)\n",
        "\n",
        "    # Remove unwanted data indices\n",
        "    if len(remove_idx) > 0:\n",
        "        remove_idx = np.hstack(remove_idx)\n",
        "        select_idx = np.setdiff1d(np.arange(len(raw_ch_df)), remove_idx)\n",
        "    else:\n",
        "        select_idx = np.arange(len(raw_ch_df))\n",
        "\n",
        "    # Intersection of selected indices with label indices\n",
        "    label_idx = np.hstack(label_idx)\n",
        "    select_idx = np.intersect1d(select_idx, label_idx)\n",
        "\n",
        "    # Remove extra labels if any\n",
        "    if len(label_idx) > len(select_idx):\n",
        "        extra_idx = np.setdiff1d(label_idx, select_idx)\n",
        "        n_label_trims = int(math.ceil(len(extra_idx) / (EPOCH_SEC_SIZE * sampling_rate)))\n",
        "        if n_label_trims != 0:\n",
        "            labels = labels[:-n_label_trims]\n",
        "\n",
        "    # Select and preprocess the relevant PSG data\n",
        "    raw_ch = raw_ch_df.values[select_idx]\n",
        "\n",
        "    # Ensure data is evenly divisible into epochs\n",
        "    if len(raw_ch) % (EPOCH_SEC_SIZE * sampling_rate) != 0:\n",
        "        raise Exception(\"Something wrong\")\n",
        "    n_epochs = len(raw_ch) / (EPOCH_SEC_SIZE * sampling_rate)\n",
        "\n",
        "    # Split data into epochs and convert labels to int32\n",
        "    x = np.asarray(np.split(raw_ch, n_epochs)).astype(np.float32)\n",
        "    y = labels.astype(np.int32)\n",
        "\n",
        "    # Find indices for non-wakeful stages and select a relevant portion\n",
        "    nw_idx = np.where(y != W)[0]\n",
        "    start_idx = nw_idx[0] - (EPOCH_SEC_SIZE * 2)\n",
        "    end_idx = nw_idx[-1] + (EPOCH_SEC_SIZE * 2)\n",
        "    if start_idx < 0: start_idx = 0\n",
        "    if end_idx >= len(y): end_idx = len(y) - 1\n",
        "    select_idx = np.arange(start_idx, end_idx + 1)\n",
        "\n",
        "    # Select data and labels based on relevant indices\n",
        "    x = x[select_idx]\n",
        "    y = y[select_idx]\n",
        "\n",
        "    return x, y, sampling_rate, h_raw, h_ann\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--data_dir\", type=str, default=\"data_edf_20\",\n",
        "                    help=\"File path to the PSG and annotation files.\")\n",
        "parser.add_argument(\"--output_dir\", type=str, default=\"data_edf_20_npz/fpzcz\",\n",
        "                    help=\"Directory where to save numpy files outputs.\")\n",
        "parser.add_argument(\"--select_ch\", type=str, default=\"EEG Fpz-Cz\",\n",
        "                    help=\"The selected channel\")\n",
        "args = parser.parse_args()\n",
        "if not os.path.exists(args.output_dir):\n",
        "    os.makedirs(args.output_dir)\n",
        "else:\n",
        "    shutil.rmtree(args.output_dir)\n",
        "    os.makedirs(args.output_dir)\n",
        "select_ch = args.select_ch\n",
        "psg_fnames = glob.glob(os.path.join(args.data_dir, \"*PSG.edf\"))\n",
        "ann_fnames = glob.glob(os.path.join(args.data_dir, \"*Hypnogram.edf\"))\n",
        "psg_fnames.sort()\n",
        "ann_fnames.sort()\n",
        "psg_fnames = np.asarray(psg_fnames)\n",
        "ann_fnames = np.asarray(ann_fnames)\n",
        "for i in range(len(psg_fnames)):\n",
        "    x, y, fs, h_raw, h_ann = load_data(psg_fnames[i], ann_fnames[i], select_ch)\n",
        "    filename = ntpath.basename(psg_fnames[i]).replace(\"-PSG.edf\", \".npz\")\n",
        "    save_dict = {\n",
        "        \"x\": x,\n",
        "        \"y\": y,\n",
        "        \"fs\": fs,\n",
        "        \"ch_label\": select_ch,\n",
        "        \"header_raw\": h_raw,\n",
        "        \"header_annotation\": h_ann,\n",
        "    }\n",
        "    np.savez(os.path.join(args.output_dir, filename), **save_dict)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "tPP0tnX8M0cp",
        "outputId": "9b820d0b-ef4a-45f8-ad35-a2a659abcda4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: colab_kernel_launcher.py [-h] [--data_dir DATA_DIR]\n",
            "                                [--output_dir OUTPUT_DIR]\n",
            "                                [--select_ch SELECT_CH]\n",
            "colab_kernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-58857c0e-8fcc-41b0-a58b-bbd2a9e63af2.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        }
      ]
    }
  ]
}